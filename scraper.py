import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import schedule
import time
import random

# Danh s√°ch c√°c m·ª•c (c√°c section tr√™n kenh14.vn)
sections = [
    {'name': 'Star', 'url': 'https://kenh14.vn/star.chn'},
    {'name': 'Cine', 'url': 'https://kenh14.vn/cine.chn'},
    {'name': 'Musik', 'url': 'https://kenh14.vn/musik.chn'},
    {'name': 'Beauty & Fashion', 'url': 'https://kenh14.vn/beauty-fashion.chn'},
    {'name': 'ƒê·ªùi s·ªëng', 'url': 'https://kenh14.vn/doi-song.chn'},
    {'name': 'Money-Z', 'url': 'https://kenh14.vn/money-z.chn'},
    {'name': 'ƒÇn - Qu·∫≠y - ƒêi', 'url': 'https://kenh14.vn/an-quay-di.chn'},
    {'name': 'S·ª©c kh·ªèe', 'url': 'https://kenh14.vn/suc-khoe.chn'},
    {'name': 'Tek-life', 'url': 'https://kenh14.vn/tek-life.chn'},
    {'name': 'H·ªçc ƒë∆∞·ªùng', 'url': 'https://kenh14.vn/hoc-duong.chn'},
    {'name': 'Xem Mua L∆∞u', 'url': 'https://kenh14.vn/xem-mua-luu.chn'},
    {'name': 'Video', 'url': 'https://kenh14.vn/video.chn'}
]

# H√†m l·∫•y tin t·ª©c t·ª´ t·ª´ng m·ª•c v·ªõi retry v√† delay
def lay_tin_tuc():
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/117.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Referer': 'https://kenh14.vn/'
    }
    all_data = []

    for section in sections:
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.get(section['url'], headers=headers, timeout=20)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')

                articles = soup.find_all('li', class_=lambda x: x and ('news' in x or 'item' in x or 'knswli' in x))
                if len(articles) < 5:
                    articles = soup.find_all('div', class_=lambda x: x and ('news' in x or 'story' in x))

                print(f"T√¨m th·∫•y {len(articles)} b√†i vi·∫øt t·ª´ m·ª•c {section['name']}")

                for article in articles:
                    try:
                        title_tag = article.find('h3', class_=lambda x: x and 'title' in x)
                        if not title_tag:
                            title_tag = article.find('h2') or article.find('a', href=True)
                        title = title_tag.get_text(strip=True) if title_tag else 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ'

                        desc_tag = article.find(lambda tag: tag.name in ['div', 'p', 'span']
                                        and tag.get('class')
                                        and any('sapo' in c or 'desc' in c or 'summary' in c for c in tag.get('class')))
                        if not desc_tag or len(desc_tag.get_text(strip=True)) < 20:
                            link_tag = article.find('a', href=True, title=True)
                            desc = link_tag['title'].strip() if link_tag and link_tag.get('title') else 'Kh√¥ng c√≥ m√¥ t·∫£'
                        else:
                            desc = desc_tag.get_text(strip=True)

                        link_tag = article.find('a', href=True)
                        link = link_tag['href'] if link_tag else ''
                        if link and not link.startswith('http'):
                            link = 'https://kenh14.vn' + link

                        img_tag = article.find('img', attrs={'src': True})
                        img = img_tag['src'] if img_tag and 'src' in img_tag.attrs else 'Kh√¥ng c√≥ h√¨nh'

                        all_data.append({
                            'M·ª•c': section['name'],
                            'Ti√™u ƒë·ªÅ': title,
                            'M√¥ t·∫£': desc,
                            'H√¨nh ·∫£nh': img,
                            'Link': link
                        })

                    except Exception as e:
                        print(f"L·ªói l·∫•y b√†i t·ª´ {section['name']}: {e}")
                        continue

                break

            except requests.RequestException as e:
                print(f"L·ªói l·∫•y trang web {section['name']} (l·∫ßn {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    wait_time = random.uniform(5, 10)
                    print(f"ƒê·ª£i {wait_time:.2f} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                    time.sleep(wait_time)
                continue
            except Exception as e:
                print(f"L·ªói kh√°c t·ª´ {section['name']}: {e}")
                break

        time.sleep(random.uniform(2, 5))

    if all_data:
        df = pd.DataFrame(all_data)
        file_name = f"kenh14_all_sections_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
        df.to_excel(file_name, index=False, engine='openpyxl')
        print(f"ƒê√£ l∆∞u file: {file_name}")
    else:
        print("Kh√¥ng l·∫•y ƒë∆∞·ª£c b√†i n√†o, ki·ªÉm tra l·∫°i!")

# L·∫•y tin t·ª©c ngay khi ch·∫°y code
#lay_tin_tuc()

# L√™n l·ªãch ch·∫°y h·∫±ng ng√†y l√∫c 6h s√°ng
schedule.every().day.at("23:25").do(lay_tin_tuc)

print("üîÑ ƒêang ch·∫°y l·ªãch h·∫±ng ng√†y. Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng.")

while True:
    schedule.run_pending()
    time.sleep(60)